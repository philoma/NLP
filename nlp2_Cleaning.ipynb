{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "l24pzBIjHmjT"
      },
      "outputs": [],
      "source": [
        "sample_text='<html> <p>We can use n-gram models with n>1,&nbsp ; ðŸ˜‚ðŸ˜Ž instead &nbsp; of the <h1>unigram language model â™¥ </h1>, providing better accuracy. But, ðŸ¤‘ at the same time, the model becomes heavy due to a higher number of calculations</p></html>'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing html tags"
      ],
      "metadata": {
        "id": "KwM2-4x_le-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xCQCyL38Ise0",
        "outputId": "4f7b5edc-e4db-4e32-be80-1e24aa90d867"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<html> <p>We can use n-gram models with n>1,&nbsp ; ðŸ˜‚ðŸ˜Ž instead &nbsp; of the <h1>unigram language model â™¥ </h1>, providing better accuracy. But, ðŸ¤‘ at the same time, the model becomes heavy due to a higher number of calculations</p></html>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://docs.python.org/3/library/re.html\n",
        "import re # RegularExpression (RegEx)\n",
        "def striphtml(data):\n",
        "  p=re.compile(r\"<.*?>\")\n",
        "  return p.sub('', data)"
      ],
      "metadata": {
        "id": "6tNp65qpJC6g"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you execute the above code you will the re.error: bad escape error because \\n and \\thas a special meaning in Python.\n",
        "\n",
        "# To avoid such issues, always write a regex pattern using a raw string. The character r denotes the raw string."
      ],
      "metadata": {
        "id": "HfYGrVYPea_4"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "striphtml(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "LzRRgsI_l0_A",
        "outputId": "0374bf96-b092-40fa-8fe2-ba06b1df7eeb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' We can use n-gram models with n>1,&nbsp ; ðŸ˜‚ðŸ˜Ž instead &nbsp; of the unigram language model â™¥ , providing better accuracy. But, ðŸ¤‘ at the same time, the model becomes heavy due to a higher number of calculations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text=striphtml(sample_text)"
      ],
      "metadata": {
        "id": "QwT2P_r5JdSL"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def striphtml(data):\n",
        "  p=re.compile(r\"&nbsp;\")\n",
        "  return p.sub('', data)"
      ],
      "metadata": {
        "id": "tXBsTPfTe_oG"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "striphtml(sample_text)\n"
      ],
      "metadata": {
        "id": "zYPTkfh3JiuN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "91d5e42f-bd6d-4929-a4f0-576688d60332"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' We can use n-gram models with n>1,&nbsp ; ðŸ˜‚ðŸ˜Ž instead  of the unigram language model â™¥ , providing better accuracy. But, ðŸ¤‘ at the same time, the model becomes heavy due to a higher number of calculations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text=striphtml(sample_text)"
      ],
      "metadata": {
        "id": "YKC6bs_QfNFf"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unicode Normalization"
      ],
      "metadata": {
        "id": "bOTbs1Rwl4Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text.encode('utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goMaLM29mPXU",
        "outputId": "ab6368f7-dd19-419a-beee-543db23d3504"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b' We can use n-gram models with n>1,&nbsp ; \\xf0\\x9f\\x98\\x82\\xf0\\x9f\\x98\\x8e instead  of the unigram language model \\xe2\\x99\\xa5 , providing better accuracy. But, \\xf0\\x9f\\xa4\\x91 at the same time, the model becomes heavy due to a higher number of calculations'"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# emojis are converted into machine understandable text"
      ],
      "metadata": {
        "id": "ZwbYMuHjmocE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spell Checking"
      ],
      "metadata": {
        "id": "tg6L3qMqm_qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text='ceertain people are wrkng in bd cnditionnnn buttt ello ppl'"
      ],
      "metadata": {
        "id": "znX_aIBJnaTW"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "H51YYHyMmzd0"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textBlb=TextBlob(incorrect_text)\n",
        "textBlb.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0PRADzAnFmP",
        "outputId": "f2015e9c-cea6-4b9a-d440-ede6dccc34cf"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"certain people are wrong in by cnditionnnn butt hello pp\")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text='certan conditionas during seveal ggenerations aree moodified in the saame maner'"
      ],
      "metadata": {
        "id": "rouSstk0pU0v"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblb=TextBlob(incorrect_text)\n",
        "textblb.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28cCtC4-nmey",
        "outputId": "16f908c8-8cf2-4125-ea80-046b26e67368"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"certain conditions during several generations are modified in the same manner\")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPB9levnpqdR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}